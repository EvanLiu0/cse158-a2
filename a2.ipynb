{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.optimize\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import xlearn as xl\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import gp_minimize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "\n",
    "  skip_count = 0\n",
    "\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    try:\n",
    "        d = eval(l)\n",
    "        u = d['user_id']\n",
    "        i = d['item_id']\n",
    "\n",
    "        if \"age\" not in d or \"size\" not in d or \"height\" not in d or \"weight\" not in d or \"body type\" not in d or \"category\" not in d:\n",
    "          skip_count += 1\n",
    "          continue\n",
    "\n",
    "        yield u,i,d\n",
    "          \n",
    "    except:\n",
    "      skip_count += 1\n",
    "      continue\n",
    "\n",
    "  print(\"Skipped %d items\" % skip_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 39434 items\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for l in parse(\"renttherunway_final_data.json.gz\"):\n",
    "    dataset.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allReviews = []\n",
    "allItems = set()\n",
    "itemCount = defaultdict(int)\n",
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem = defaultdict(set)\n",
    "allUI = {}\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "totalReviews = 0\n",
    "\n",
    "for u, i, d in dataset:\n",
    "  allReviews.append((u, i, d))\n",
    "  allItems.add(i)\n",
    "  itemCount[i] += 1\n",
    "  totalReviews += 1\n",
    "  itemsPerUser[u].add(i)\n",
    "  usersPerItem[i].add(u)\n",
    "  allUI[(u, i)] = int(d['rating'])\n",
    "  ratingsPerUser[u].append(int(d['rating']))\n",
    "  ratingsPerItem[i].append(int(d['rating']))\n",
    "\n",
    "mostPopular = [(itemCount[x], x) for x in itemCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostPopular(threshold):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > threshold: break\n",
    "\n",
    "    return return1\n",
    "\n",
    "def getLeastPopular(threshold):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "\n",
    "    for ic, i in reversed(mostPopular):\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > threshold: break\n",
    "\n",
    "    return return1\n",
    "\n",
    "def getAccuracy(preds):\n",
    "    correctCount = 0\n",
    "\n",
    "    for p in preds:\n",
    "        if (p[2] == 1 and p[1] in itemsPerUser[p[0]]) or (p[2] == 0 and p[1] not in itemsPerUser[p[0]]):\n",
    "            # print(\"Correct: \", p)\n",
    "            correctCount += 1\n",
    "\n",
    "    baselineAccuracy = correctCount / len(preds)\n",
    "\n",
    "    return baselineAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_threshold = int(len(allReviews)*.7)\n",
    "\n",
    "ratingsTrain = allReviews[:split_threshold]\n",
    "ratingsValid = allReviews[split_threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs, itemIDs = {}, {}\n",
    "interactions = []\n",
    "\n",
    "for user, item, details in allReviews:\n",
    "    user = details['user_id']\n",
    "    item = details['item_id']\n",
    "    rating = int(details['rating'])\n",
    "\n",
    "    if not user in userIDs: userIDs[user] = len(userIDs)\n",
    "    if not item in itemIDs: itemIDs[item] = len(itemIDs)\n",
    "    interactions.append((user, item, rating))\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDsTrain, itemIDsTrain = {}, {}\n",
    "userIDsValid, itemIDsValid = {}, {}\n",
    "\n",
    "for u, i, d in ratingsTrain:\n",
    "    if not u in userIDsTrain:\n",
    "        userIDsTrain[u] = len(userIDsTrain)\n",
    "    if not i in itemIDsTrain:\n",
    "        itemIDsTrain[i] = len(itemIDsTrain)\n",
    "\n",
    "for u, i, d in ratingsValid:\n",
    "    if not u in userIDsValid:\n",
    "        userIDsValid[u] = len(userIDsValid)\n",
    "    if not i in itemIDsValid:\n",
    "        itemIDsValid[i] = len(itemIDsValid)\n",
    "\n",
    "nUsersTrain, nItemsTrain = len(userIDsTrain), len(itemIDsTrain)\n",
    "nUsersValid, nItemsValid = len(userIDsValid), len(itemIDsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll = []\n",
    "dataTrain = []\n",
    "dataValid = []\n",
    "allRatings = []\n",
    "\n",
    "for u, i, d in allReviews:\n",
    "    dataAll.append(d)\n",
    "    allRatings.append(int(d['rating']))\n",
    "\n",
    "global_median = int(statistics.median(allRatings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PREDICTION TASK 1.1: BPR PREDICTION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(itemIDs.keys())\n",
    "\n",
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super(BPRbatch, self).__init__()\n",
    "        # Initialize variables\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.betaI) +\\\n",
    "                            tf.nn.l2_loss(self.gammaU) +\\\n",
    "                            tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBPR(model, interactions, optimizer):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleJ = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,_ = random.choice(interactions) # positive sample\n",
    "            j = random.choice(items) # negative sample\n",
    "            while j in itemsPerUser[u]:\n",
    "                j = random.choice(items)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleJ.append(itemIDs[j])\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleJ)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "leastPop = getLeastPopular(len(allItems) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bprPredict(user, item, modelBPR):\n",
    "    if item in leastPop:\n",
    "        return 0\n",
    "    else:\n",
    "        ind_bpr = modelBPR.predict(userIDs[user], itemIDs[item]).numpy()\n",
    "        if ind_bpr > 0.4:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeSamples(dataset):\n",
    "    negativeSamples = []\n",
    "    \n",
    "    for d in dataset:\n",
    "        user = d[0]\n",
    "\n",
    "        # randomly select an item that the user has not reviewed\n",
    "        notReviewed = allItems - itemsPerUser[user]\n",
    "        notReviewed = list(notReviewed)\n",
    "        # pick a random index in notReviewed\n",
    "        rand_ind = random.randint(0, len(notReviewed) - 1)\n",
    "        newItem = notReviewed[rand_ind]\n",
    "\n",
    "        negativeSamples.append((user, newItem, 0))\n",
    "\n",
    "    return negativeSamples + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bprCV(k):\n",
    "\n",
    "    folds = []\n",
    "    accuracies = []\n",
    "\n",
    "    fold_size = int(len(interactions) / k)\n",
    "\n",
    "    for fold in range(k):\n",
    "        folds.append(interactions[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "    for fold in range(k):\n",
    "\n",
    "        currValid = folds[fold]\n",
    "        currTraining = []\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "        # 5 latent factors default\n",
    "        modelBPR = BPRbatch(5, 0.00001)\n",
    "\n",
    "        for j in range(k):\n",
    "            if j != fold:\n",
    "                currTraining += folds[j]\n",
    "\n",
    "        print(\"===========================\\n\")\n",
    "\n",
    "        for i in range(30):\n",
    "            obj = trainingStepBPR(modelBPR, currTraining, optimizer)\n",
    "            if (i % 10 == 9): print(f\"Fold {fold} iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "\n",
    "        validPreds = []\n",
    "\n",
    "        negativeValid = getNegativeSamples(currValid)\n",
    "\n",
    "        for u, i, _ in negativeValid:\n",
    "            validPreds.append((u, i, bprPredict(u, i, modelBPR)))\n",
    "\n",
    "        curr_acc = getAccuracy(validPreds)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"Fold {fold} Validation Accuracy: {curr_acc}\")\n",
    "        print(\"\\n===========================\")\n",
    "\n",
    "        accuracies.append(curr_acc)\n",
    "\n",
    "    print(f\"Average Accuracy Across {k} Folds: {sum(accuracies) / len(accuracies)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Fold 0 iteration 10, objective = 0.46806264\n",
      "Fold 0 iteration 20, objective = 0.42419165\n",
      "Fold 0 iteration 30, objective = 0.42145234\n",
      "Fold 0 iteration 40, objective = 0.41671234\n",
      "Fold 0 iteration 50, objective = 0.40817404\n",
      "\n",
      "\n",
      "Fold 0 Validation Accuracy: 0.7481712494285154\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 1 iteration 10, objective = 0.4696231\n",
      "Fold 1 iteration 20, objective = 0.42380306\n",
      "Fold 1 iteration 30, objective = 0.41693705\n",
      "Fold 1 iteration 40, objective = 0.41588974\n",
      "Fold 1 iteration 50, objective = 0.41044435\n",
      "\n",
      "\n",
      "Fold 1 Validation Accuracy: 0.7490692965841552\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 2 iteration 10, objective = 0.46994984\n",
      "Fold 2 iteration 20, objective = 0.41997802\n",
      "Fold 2 iteration 30, objective = 0.4174055\n",
      "Fold 2 iteration 40, objective = 0.41531417\n",
      "Fold 2 iteration 50, objective = 0.409226\n",
      "\n",
      "\n",
      "Fold 2 Validation Accuracy: 0.7500979687806153\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 3 iteration 10, objective = 0.46958163\n",
      "Fold 3 iteration 20, objective = 0.42584887\n",
      "Fold 3 iteration 30, objective = 0.42156363\n",
      "Fold 3 iteration 40, objective = 0.4158792\n",
      "Fold 3 iteration 50, objective = 0.41239652\n",
      "\n",
      "\n",
      "Fold 3 Validation Accuracy: 0.7495264842270263\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 4 iteration 10, objective = 0.47073227\n",
      "Fold 4 iteration 20, objective = 0.42728904\n",
      "Fold 4 iteration 30, objective = 0.42494392\n",
      "Fold 4 iteration 40, objective = 0.41922218\n",
      "Fold 4 iteration 50, objective = 0.41161558\n",
      "\n",
      "\n",
      "Fold 4 Validation Accuracy: 0.7516328130102541\n",
      "\n",
      "===========================\n",
      "\n",
      "\n",
      "Average Accuracy Across 5 Folds: 0.7496995624061134\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bprCV(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PREDICTION TASK 1.2: NEURAL COLLABORATIVE FILTERING PREDICTION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create negative samples\n",
    "\n",
    "temp = getNegativeSamples(interactions)\n",
    "interactions_net = []\n",
    "\n",
    "for i in temp:\n",
    "    if i[2] != 0:\n",
    "        interactions_net.append((i[0], i[1], 1))\n",
    "    else:\n",
    "        interactions_net.append((i[0], i[1], 0))\n",
    "\n",
    "# convert interactions to dataframe\n",
    "interactions_df = pd.DataFrame(interactions_net, columns=['user', 'item', 'rating'])\n",
    "interactions_df['user_index'] = interactions_df['user'].apply(lambda x: userIDs[x])\n",
    "interactions_df['item_index'] = interactions_df['item'].apply(lambda x: itemIDs[x])\n",
    "interactions_df['positive_interaction'] = interactions_df['rating']\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(interactions_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NCF model using TensorFlow's Keras API\n",
    "def create_ncf_model(num_users, num_items, embedding_size=64):\n",
    "    user_input = Input(shape=(1,))\n",
    "    item_input = Input(shape=(1,))\n",
    "\n",
    "    user_embedding = Embedding(num_users, embedding_size)(user_input)\n",
    "    item_embedding = Embedding(num_items, embedding_size)(item_input)\n",
    "\n",
    "    concat = Concatenate()([user_embedding, item_embedding])\n",
    "    flatten = Flatten()(concat)\n",
    "    dense_layer = Dense(64, activation='relu')(flatten)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input], outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = interactions_df['user_index'].nunique()\n",
    "num_items = interactions_df['item_index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6699/6699 [==============================] - 630s 93ms/step - loss: 0.5422 - accuracy: 0.7182 - val_loss: 0.5208 - val_accuracy: 0.7325\n",
      "Epoch 2/3\n",
      "6699/6699 [==============================] - 555s 83ms/step - loss: 0.4545 - accuracy: 0.7743 - val_loss: 0.5367 - val_accuracy: 0.7219\n",
      "Epoch 3/3\n",
      "6699/6699 [==============================] - 834s 125ms/step - loss: 0.3534 - accuracy: 0.8383 - val_loss: 0.5873 - val_accuracy: 0.7025\n"
     ]
    }
   ],
   "source": [
    "ncf_model = create_ncf_model(num_users, num_items)\n",
    "\n",
    "history = ncf_model.fit(\n",
    "    [train_df['user_index'], train_df['item_index']],\n",
    "    train_df['positive_interaction'],\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    validation_data=([test_df['user_index'], test_df['item_index']], test_df['positive_interaction'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.0: BASELINE REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9140704939803626\n"
     ]
    }
   ],
   "source": [
    "y_baseline = []\n",
    "y_true = []\n",
    "\n",
    "for u, i, d in ratingsValid:\n",
    "    y_true.append(int(d['rating']))\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    y_baseline.append(global_median)\n",
    "    \n",
    "print(mean_squared_error(y_true, y_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.1: LATENT FACTOR REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update alpha, beta_u, and beta_i until convergence\n",
    "\n",
    "def iterate(lamb, alpha_old, betaU_old, betaI_old, reviewsTrain, trainRatings):\n",
    "\n",
    "    betaU_new = {}\n",
    "    betaI_new = {}\n",
    "\n",
    "    alpha_num = 0\n",
    "    for u, i, _ in reviewsTrain:\n",
    "        alpha_num += allUI[(u, i)] - (betaU_old[u] + betaI_old[i])\n",
    "    alpha_new = alpha_num / len(reviewsTrain)\n",
    "\n",
    "    for u in itemsPerUser:\n",
    "        beta_u_num = 0\n",
    "        for i in itemsPerUser[u]:\n",
    "            beta_u_num += allUI[(u, i)] - (alpha_new + betaI_old[i])\n",
    "        betaU_new[u] = beta_u_num / (lamb + len(itemsPerUser[u]))\n",
    "\n",
    "    for i in usersPerItem:\n",
    "        beta_i_num = 0\n",
    "        for u in usersPerItem[i]:\n",
    "            beta_i_num += allUI[(u, i)] - (alpha_new + betaU_old[u])\n",
    "        betaI_new[i] = beta_i_num / (lamb + len(usersPerItem[i]))\n",
    "    \n",
    "    if abs(alpha_new - alpha_old) > 0.005:\n",
    "        return iterate(lamb, alpha_new, betaU_new, betaI_new, reviewsTrain, trainRatings)\n",
    "    else:\n",
    "        return alpha_new, betaU_new, betaI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LatentFactorCV(k):\n",
    "\n",
    "    mses = []\n",
    "\n",
    "    # shuffle allReviews\n",
    "    random.shuffle(allReviews)\n",
    "\n",
    "    # split into k folds\n",
    "    folds = []\n",
    "    fold_size = int(len(allReviews) / k)\n",
    "\n",
    "    for fold in range(k):\n",
    "        folds.append(allReviews[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "    for fold in range(k):\n",
    "\n",
    "        betaU = {}\n",
    "        betaI = {}\n",
    "\n",
    "        for u in ratingsPerUser:\n",
    "            betaU[u] = 0\n",
    "\n",
    "        for g in ratingsPerItem:\n",
    "            betaI[g] = 0\n",
    "\n",
    "        currValidation = folds[fold]\n",
    "\n",
    "        # use every other fold as training\n",
    "        currTraining = []\n",
    "\n",
    "        for j in range(k):\n",
    "            if j != fold:\n",
    "                currTraining += folds[j]\n",
    "        \n",
    "        trainRatings = []\n",
    "        validRatings = []\n",
    "\n",
    "        for user, item, details in currTraining:\n",
    "            trainRatings.append(int(details['rating']))\n",
    "\n",
    "        for user, item, details in currValidation:\n",
    "            validRatings.append(int(details['rating']))\n",
    "\n",
    "        alpha = global_median\n",
    "\n",
    "        final_alpha, betaU_new, betaI_new = iterate(4.3, alpha, betaU, betaI, currTraining, trainRatings)\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        for user, item, details in currValidation:\n",
    "            y_pred.append(final_alpha + betaU_new[user] + betaI_new[item])\n",
    "\n",
    "        validMSE = mean_squared_error(validRatings, y_pred)\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"Fold K = {int(fold)+1}, Validation MSE: {validMSE}\")\n",
    "        print(\"=====================================\")\n",
    "\n",
    "        mses.append(validMSE)\n",
    "\n",
    "    avg_mse = sum(mses) / len(mses)\n",
    "\n",
    "    print(\"=====================================\\n\")\n",
    "    print(f\"Average {k}-Fold Gradient Descent CV MSE: {avg_mse}\")\n",
    "    print(\"\\n=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Fold K = 1, Validation MSE: 1.3836023007282647\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 2, Validation MSE: 1.3811487286133814\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 3, Validation MSE: 1.3430821002561888\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 4, Validation MSE: 1.3711317674868169\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 5, Validation MSE: 1.3680693041942387\n",
      "=====================================\n",
      "=====================================\n",
      "\n",
      "Average 5-Fold Gradient Descent CV MSE: 1.369406840255778\n",
      "\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "LatentFactorCV(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.2: FACTORIZATION MACHINE REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_height_to_inches(height_str):\n",
    "    feet = int(height_str.split(\"'\")[0])\n",
    "    inches = int(height_str.split(\"'\")[1][1:-1])\n",
    "    height_inches = feet * 12 + inches\n",
    "\n",
    "    return height_inches\n",
    "\n",
    "def convert_weight_to_lbs(weight_str):\n",
    "    weight_lbs = int(weight_str[:-3])\n",
    "\n",
    "    return weight_lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'] = df['height'].apply(convert_height_to_inches)\n",
    "df['weight'] = df['weight'].apply(convert_weight_to_lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_rented = pd.get_dummies(df['rented for'])\n",
    "one_hot_btype = pd.get_dummies(df['body type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user_id', 'item_id', 'review_date', 'review_summary', 'review_text', 'rented for', 'body type', 'category'], axis=1)\n",
    "df = pd.concat([df, one_hot_rented, one_hot_btype], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "libsvm_data = df.apply(\n",
    "    lambda row: f\"{row['rating']} 1:{row['age']} 2:{row['size']} 3:{row['height']} 4:{row['weight']} \"\n",
    "    + \" \".join([f\"{i + 5}:{value}\" for i, value in enumerate(row.iloc[7:])]) + \"\\n\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as f:\n",
    "    f.writelines(libsvm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm_model = xl.create_fm() # Use field-aware factorization machine (ffm)\n",
    "ffm_model.setTrain(\"./train.txt\")    # Set the path of training dataset\n",
    "\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.02, 'epoch':3, 'fold':5, 'k':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Cross-validation doesn't support early-stopping. xLearn has already close early-stopping.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_0.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_1.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_2.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_3.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_4.bin) NOT found. Convert text file to binary file.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 21\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.10 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.48 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 1/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.049336            1.019645                0.78\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.038737            1.014686                1.01\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.038473            1.015306                0.92\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 2/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.044861            1.036598                0.80\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.033269            1.036510                0.87\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.033076            1.036665                0.88\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 3/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.040968            1.041951                0.82\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.031929            1.042029                1.51\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.031685            1.042401                1.20\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 4/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.044893            1.035274                1.07\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.033703            1.034434                1.08\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.033656            1.034080                0.90\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 5/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.043458            1.040631                0.78\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.032345            1.040791                0.87\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.032173            1.040599                0.86\n",
      "\u001b[32m[------------] \u001b[0mAverage mse_loss: 1.033810\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish Cross-Validation\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 22.48 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ffm_model.cv(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
