{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.optimize\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import xlearn as xl\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import gp_minimize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "\n",
    "  skip_count = 0\n",
    "\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    try:\n",
    "        d = eval(l)\n",
    "        u = d['user_id']\n",
    "        i = d['item_id']\n",
    "\n",
    "        if \"age\" not in d or \"size\" not in d or \"height\" not in d or \"weight\" not in d or \"body type\" not in d or \"category\" not in d:\n",
    "          skip_count += 1\n",
    "          continue\n",
    "\n",
    "        yield u,i,d\n",
    "          \n",
    "    except:\n",
    "      skip_count += 1\n",
    "      continue\n",
    "\n",
    "  print(\"Skipped %d items\" % skip_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 39434 items\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for l in parse(\"renttherunway_final_data.json.gz\"):\n",
    "    dataset.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allReviews = []\n",
    "allItems = set()\n",
    "itemCount = defaultdict(int)\n",
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem = defaultdict(set)\n",
    "allUI = {}\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "\n",
    "totalReviews = 0\n",
    "\n",
    "for u, i, d in dataset:\n",
    "  allReviews.append((u, i, d))\n",
    "  allItems.add(i)\n",
    "  itemCount[i] += 1\n",
    "  totalReviews += 1\n",
    "  itemsPerUser[u].add(i)\n",
    "  usersPerItem[i].add(u)\n",
    "  allUI[(u, i)] = int(d['rating'])\n",
    "  ratingsPerUser[u].append(int(d['rating']))\n",
    "  ratingsPerItem[i].append(int(d['rating']))\n",
    "\n",
    "mostPopular = [(itemCount[x], x) for x in itemCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostPopular(threshold):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > threshold: break\n",
    "\n",
    "    return return1\n",
    "\n",
    "def getLeastPopular(threshold):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "\n",
    "    for ic, i in reversed(mostPopular):\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > threshold: break\n",
    "\n",
    "    return return1\n",
    "\n",
    "def getAccuracy(preds):\n",
    "    correctCount = 0\n",
    "\n",
    "    for p in preds:\n",
    "        if (p[2] == 1 and p[1] in itemsPerUser[p[0]]) or (p[2] == 0 and p[1] not in itemsPerUser[p[0]]):\n",
    "            # print(\"Correct: \", p)\n",
    "            correctCount += 1\n",
    "\n",
    "    baselineAccuracy = correctCount / len(preds)\n",
    "\n",
    "    return baselineAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_threshold = int(len(allReviews)*.7)\n",
    "\n",
    "ratingsTrain = allReviews[:split_threshold]\n",
    "ratingsValid = allReviews[split_threshold:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDs, itemIDs = {}, {}\n",
    "interactions = []\n",
    "\n",
    "for user, item, details in allReviews:\n",
    "    user = details['user_id']\n",
    "    item = details['item_id']\n",
    "    rating = int(details['rating'])\n",
    "\n",
    "    if not user in userIDs: userIDs[user] = len(userIDs)\n",
    "    if not item in itemIDs: itemIDs[item] = len(itemIDs)\n",
    "    interactions.append((user, item, rating))\n",
    "\n",
    "nUsers, nItems = len(userIDs), len(itemIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "userIDsTrain, itemIDsTrain = {}, {}\n",
    "userIDsValid, itemIDsValid = {}, {}\n",
    "\n",
    "for u, i, d in ratingsTrain:\n",
    "    if not u in userIDsTrain:\n",
    "        userIDsTrain[u] = len(userIDsTrain)\n",
    "    if not i in itemIDsTrain:\n",
    "        itemIDsTrain[i] = len(itemIDsTrain)\n",
    "\n",
    "for u, i, d in ratingsValid:\n",
    "    if not u in userIDsValid:\n",
    "        userIDsValid[u] = len(userIDsValid)\n",
    "    if not i in itemIDsValid:\n",
    "        itemIDsValid[i] = len(itemIDsValid)\n",
    "\n",
    "nUsersTrain, nItemsTrain = len(userIDsTrain), len(itemIDsTrain)\n",
    "nUsersValid, nItemsValid = len(userIDsValid), len(itemIDsValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAll = []\n",
    "dataTrain = []\n",
    "dataValid = []\n",
    "allRatings = []\n",
    "\n",
    "for u, i, d in allReviews:\n",
    "    dataAll.append(d)\n",
    "    allRatings.append(int(d['rating']))\n",
    "\n",
    "global_median = int(statistics.median(allRatings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PREDICTION TASK 1.1: BPR PREDICTION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(itemIDs.keys())\n",
    "\n",
    "class BPRbatch(tf.keras.Model):\n",
    "    def __init__(self, K, lamb):\n",
    "        super(BPRbatch, self).__init__()\n",
    "        # Initialize variables\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.gammaU = tf.Variable(tf.random.normal([len(userIDs),K],stddev=0.001))\n",
    "        self.gammaI = tf.Variable(tf.random.normal([len(itemIDs),K],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    def predict(self, u, i):\n",
    "        p = self.betaI[i] + tf.tensordot(self.gammaU[u], self.gammaI[i], 1)\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.nn.l2_loss(self.betaI) +\\\n",
    "                            tf.nn.l2_loss(self.gammaU) +\\\n",
    "                            tf.nn.l2_loss(self.gammaI))\n",
    "    \n",
    "    def score(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        gamma_u = tf.nn.embedding_lookup(self.gammaU, u)\n",
    "        gamma_i = tf.nn.embedding_lookup(self.gammaI, i)\n",
    "        x_ui = beta_i + tf.reduce_sum(tf.multiply(gamma_u, gamma_i), 1)\n",
    "        return x_ui\n",
    "\n",
    "    def call(self, sampleU, sampleI, sampleJ):\n",
    "        x_ui = self.score(sampleU, sampleI)\n",
    "        x_uj = self.score(sampleU, sampleJ)\n",
    "        return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_ui - x_uj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingStepBPR(model, interactions, optimizer):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleJ = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,_ = random.choice(interactions) # positive sample\n",
    "            j = random.choice(items) # negative sample\n",
    "            while j in itemsPerUser[u]:\n",
    "                j = random.choice(items)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleJ.append(itemIDs[j])\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleJ)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "                              (grad, var) in zip(gradients, model.trainable_variables)\n",
    "                              if grad is not None)\n",
    "    return loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "leastPop = getLeastPopular(len(allItems) / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bprPredict(user, item, modelBPR):\n",
    "    if item in leastPop:\n",
    "        return 0\n",
    "    else:\n",
    "        ind_bpr = modelBPR.predict(userIDs[user], itemIDs[item]).numpy()\n",
    "        if ind_bpr > 0.4:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegativeSamples(dataset):\n",
    "    negativeSamples = []\n",
    "    \n",
    "    for d in dataset:\n",
    "        user = d[0]\n",
    "\n",
    "        # randomly select an item that the user has not reviewed\n",
    "        notReviewed = allItems - itemsPerUser[user]\n",
    "        notReviewed = list(notReviewed)\n",
    "        # pick a random index in notReviewed\n",
    "        rand_ind = random.randint(0, len(notReviewed) - 1)\n",
    "        newItem = notReviewed[rand_ind]\n",
    "\n",
    "        negativeSamples.append((user, newItem, 0))\n",
    "\n",
    "    return negativeSamples + dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bprCV(k):\n",
    "\n",
    "    folds = []\n",
    "    accuracies = []\n",
    "\n",
    "    fold_size = int(len(interactions) / k)\n",
    "\n",
    "    for fold in range(k):\n",
    "        folds.append(interactions[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "    for fold in range(k):\n",
    "\n",
    "        currValid = folds[fold]\n",
    "        currTraining = []\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(0.1)\n",
    "        # 5 latent factors default\n",
    "        modelBPR = BPRbatch(5, 0.00001)\n",
    "\n",
    "        for j in range(k):\n",
    "            if j != fold:\n",
    "                currTraining += folds[j]\n",
    "\n",
    "        print(\"===========================\")\n",
    "\n",
    "        for i in range(30):\n",
    "            obj = trainingStepBPR(modelBPR, currTraining, optimizer)\n",
    "            if (i % 10 == 9): print(f\"Fold {fold} iteration \" + str(i+1) + \", objective = \" + str(obj))\n",
    "\n",
    "        validPreds = []\n",
    "\n",
    "        negativeValid = getNegativeSamples(currValid)\n",
    "\n",
    "        for u, i, _ in negativeValid:\n",
    "            validPreds.append((u, i, bprPredict(u, i, modelBPR)))\n",
    "\n",
    "        curr_acc = getAccuracy(validPreds)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"Fold {fold} Validation Accuracy: {curr_acc}\")\n",
    "        print(\"\\n===========================\")\n",
    "\n",
    "        accuracies.append(curr_acc)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Average Accuracy Across {k} Folds: {sum(accuracies) / len(accuracies)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================\n",
      "Fold 0 iteration 10, objective = 0.46806264\n",
      "Fold 0 iteration 20, objective = 0.42419165\n",
      "Fold 0 iteration 30, objective = 0.42145234\n",
      "Fold 0 iteration 40, objective = 0.41671234\n",
      "Fold 0 iteration 50, objective = 0.40817404\n",
      "\n",
      "\n",
      "Fold 0 Validation Accuracy: 0.7481712494285154\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 1 iteration 10, objective = 0.4696231\n",
      "Fold 1 iteration 20, objective = 0.42380306\n",
      "Fold 1 iteration 30, objective = 0.41693705\n",
      "Fold 1 iteration 40, objective = 0.41588974\n",
      "Fold 1 iteration 50, objective = 0.41044435\n",
      "\n",
      "\n",
      "Fold 1 Validation Accuracy: 0.7490692965841552\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 2 iteration 10, objective = 0.46994984\n",
      "Fold 2 iteration 20, objective = 0.41997802\n",
      "Fold 2 iteration 30, objective = 0.4174055\n",
      "Fold 2 iteration 40, objective = 0.41531417\n",
      "Fold 2 iteration 50, objective = 0.409226\n",
      "\n",
      "\n",
      "Fold 2 Validation Accuracy: 0.7500979687806153\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 3 iteration 10, objective = 0.46958163\n",
      "Fold 3 iteration 20, objective = 0.42584887\n",
      "Fold 3 iteration 30, objective = 0.42156363\n",
      "Fold 3 iteration 40, objective = 0.4158792\n",
      "Fold 3 iteration 50, objective = 0.41239652\n",
      "\n",
      "\n",
      "Fold 3 Validation Accuracy: 0.7495264842270263\n",
      "\n",
      "===========================\n",
      "===========================\n",
      "Fold 4 iteration 10, objective = 0.47073227\n",
      "Fold 4 iteration 20, objective = 0.42728904\n",
      "Fold 4 iteration 30, objective = 0.42494392\n",
      "Fold 4 iteration 40, objective = 0.41922218\n",
      "Fold 4 iteration 50, objective = 0.41161558\n",
      "\n",
      "\n",
      "Fold 4 Validation Accuracy: 0.7516328130102541\n",
      "\n",
      "===========================\n",
      "\n",
      "\n",
      "Average Accuracy Across 5 Folds: 0.7496995624061134\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bprCV(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### PREDICTION TASK 1.2: NEURAL COLLABORATIVE FILTERING PREDICTION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'raw_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j3/vqqg7s3n5rn3rx7rfc213ly00000gn/T/ipykernel_21507/3511287443.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_index'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitemIDs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'positive_interaction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minteractions_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# split into train and test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data, test_size, train_size, random_state, shuffle)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     )\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         test_size, train_size = self.validate_train_test_sizes(\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.11.4/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'raw_ratings'"
     ]
    }
   ],
   "source": [
    "# create negative samples\n",
    "\n",
    "temp = getNegativeSamples(interactions)\n",
    "interactions_net = []\n",
    "\n",
    "for i in temp:\n",
    "    if i[2] != 0:\n",
    "        interactions_net.append((i[0], i[1], 1))\n",
    "    else:\n",
    "        interactions_net.append((i[0], i[1], 0))\n",
    "\n",
    "# convert interactions to dataframe\n",
    "interactions_df = pd.DataFrame(interactions_net, columns=['user', 'item', 'rating'])\n",
    "interactions_df['user_index'] = interactions_df['user'].apply(lambda x: userIDs[x])\n",
    "interactions_df['item_index'] = interactions_df['item'].apply(lambda x: itemIDs[x])\n",
    "interactions_df['positive_interaction'] = interactions_df['rating']\n",
    "\n",
    "# split into train and test\n",
    "train_df, test_df = train_test_split(interactions_df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NCF model using TensorFlow's Keras API\n",
    "def create_ncf_model(num_users, num_items, embedding_size=64):\n",
    "    user_input = Input(shape=(1,))\n",
    "    item_input = Input(shape=(1,))\n",
    "\n",
    "    user_embedding = Embedding(num_users, embedding_size)(user_input)\n",
    "    item_embedding = Embedding(num_items, embedding_size)(item_input)\n",
    "\n",
    "    concat = Concatenate()([user_embedding, item_embedding])\n",
    "    flatten = Flatten()(concat)\n",
    "    dense_layer = Dense(64, activation='relu')(flatten)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense_layer)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input], outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = interactions_df['user_index'].nunique()\n",
    "num_items = interactions_df['item_index'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7896/7896 [==============================] - 508s 64ms/step - loss: 0.5053 - accuracy: 0.7521 - val_loss: 0.4709 - val_accuracy: 0.7753\n",
      "Epoch 2/3\n",
      "7896/7896 [==============================] - 545s 69ms/step - loss: 0.4006 - accuracy: 0.8105 - val_loss: 0.4878 - val_accuracy: 0.7627\n",
      "Epoch 3/3\n",
      "7896/7896 [==============================] - 547s 69ms/step - loss: 0.2946 - accuracy: 0.8690 - val_loss: 0.5678 - val_accuracy: 0.7465\n"
     ]
    }
   ],
   "source": [
    "ncf_model = create_ncf_model(num_users, num_items)\n",
    "\n",
    "history = ncf_model.fit(\n",
    "    [train_df['user_index'], train_df['item_index']],\n",
    "    train_df['positive_interaction'],\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    validation_data=([test_df['user_index'], test_df['item_index']], test_df['positive_interaction'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.0: BASELINE REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_baseline = []\n",
    "y_true = []\n",
    "\n",
    "for u, i, d in ratingsValid:\n",
    "    y_true.append(int(d['rating']))\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    y_baseline.append(global_median)\n",
    "    \n",
    "print(mean_squared_error(y_true, y_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.1: LATENT FACTOR REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update alpha, beta_u, and beta_i until convergence\n",
    "\n",
    "def iterate(lamb, alpha_old, betaU_old, betaI_old, reviewsTrain, trainRatings):\n",
    "\n",
    "    betaU_new = {}\n",
    "    betaI_new = {}\n",
    "\n",
    "    alpha_num = 0\n",
    "    for u, i, _ in reviewsTrain:\n",
    "        alpha_num += allUI[(u, i)] - (betaU_old[u] + betaI_old[i])\n",
    "    alpha_new = alpha_num / len(reviewsTrain)\n",
    "\n",
    "    for u in itemsPerUser:\n",
    "        beta_u_num = 0\n",
    "        for i in itemsPerUser[u]:\n",
    "            beta_u_num += allUI[(u, i)] - (alpha_new + betaI_old[i])\n",
    "        betaU_new[u] = beta_u_num / (lamb + len(itemsPerUser[u]))\n",
    "\n",
    "    for i in usersPerItem:\n",
    "        beta_i_num = 0\n",
    "        for u in usersPerItem[i]:\n",
    "            beta_i_num += allUI[(u, i)] - (alpha_new + betaU_old[u])\n",
    "        betaI_new[i] = beta_i_num / (lamb + len(usersPerItem[i]))\n",
    "    \n",
    "    if abs(alpha_new - alpha_old) > 0.005:\n",
    "        return iterate(lamb, alpha_new, betaU_new, betaI_new, reviewsTrain, trainRatings)\n",
    "    else:\n",
    "        return alpha_new, betaU_new, betaI_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LatentFactorCV(k):\n",
    "\n",
    "    mses = []\n",
    "\n",
    "    # shuffle allReviews\n",
    "    random.shuffle(allReviews)\n",
    "\n",
    "    # split into k folds\n",
    "    folds = []\n",
    "    fold_size = int(len(allReviews) / k)\n",
    "\n",
    "    for fold in range(k):\n",
    "        folds.append(allReviews[fold * fold_size : (fold + 1) * fold_size])\n",
    "\n",
    "    for fold in range(k):\n",
    "\n",
    "        betaU = {}\n",
    "        betaI = {}\n",
    "\n",
    "        for u in ratingsPerUser:\n",
    "            betaU[u] = 0\n",
    "\n",
    "        for g in ratingsPerItem:\n",
    "            betaI[g] = 0\n",
    "\n",
    "        currValidation = folds[fold]\n",
    "\n",
    "        # use every other fold as training\n",
    "        currTraining = []\n",
    "\n",
    "        for j in range(k):\n",
    "            if j != fold:\n",
    "                currTraining += folds[j]\n",
    "        \n",
    "        trainRatings = []\n",
    "        validRatings = []\n",
    "\n",
    "        for user, item, details in currTraining:\n",
    "            trainRatings.append(int(details['rating']))\n",
    "\n",
    "        for user, item, details in currValidation:\n",
    "            validRatings.append(int(details['rating']))\n",
    "\n",
    "        alpha = global_median\n",
    "\n",
    "        final_alpha, betaU_new, betaI_new = iterate(4.3, alpha, betaU, betaI, currTraining, trainRatings)\n",
    "\n",
    "        y_pred = []\n",
    "\n",
    "        for user, item, details in currValidation:\n",
    "            y_pred.append(final_alpha + betaU_new[user] + betaI_new[item])\n",
    "\n",
    "        validMSE = mean_squared_error(validRatings, y_pred)\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"Fold K = {int(fold)+1}, Validation MSE: {validMSE}\")\n",
    "        print(\"=====================================\")\n",
    "\n",
    "        mses.append(validMSE)\n",
    "\n",
    "    avg_mse = sum(mses) / len(mses)\n",
    "\n",
    "    print(\"=====================================\\n\")\n",
    "    print(f\"Average {k}-Fold Gradient Descent CV MSE: {avg_mse}\")\n",
    "    print(\"\\n=====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================\n",
      "Fold K = 1, Validation MSE: 1.3601847766252928\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 2, Validation MSE: 1.3828149511704142\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 3, Validation MSE: 1.3732938324618142\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 4, Validation MSE: 1.3734536419119359\n",
      "=====================================\n",
      "=====================================\n",
      "Fold K = 5, Validation MSE: 1.3563587234919026\n",
      "=====================================\n",
      "=====================================\n",
      "\n",
      "Average 5-Fold Gradient Descent CV MSE: 1.3692211851322718\n",
      "\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "LatentFactorCV(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### TASK 2.2: FACTORIZATION MACHINE REGRESSION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_height_to_inches(height_str):\n",
    "    feet = int(height_str.split(\"'\")[0])\n",
    "    inches = int(height_str.split(\"'\")[1][1:-1])\n",
    "    height_inches = feet * 12 + inches\n",
    "\n",
    "    return height_inches\n",
    "\n",
    "def convert_weight_to_lbs(weight_str):\n",
    "    weight_lbs = int(weight_str[:-3])\n",
    "\n",
    "    return weight_lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'] = df['height'].apply(convert_height_to_inches)\n",
    "df['weight'] = df['weight'].apply(convert_weight_to_lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_rented = pd.get_dummies(df['rented for'])\n",
    "one_hot_btype = pd.get_dummies(df['body type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['user_id', 'item_id', 'review_date', 'review_summary', 'review_text', 'rented for', 'body type', 'category'], axis=1)\n",
    "df = pd.concat([df, one_hot_rented, one_hot_btype], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libsvm_data = df.apply(\n",
    "    lambda row: f\"{row['rating']} 1:{row['age']} 2:{row['size']} 3:{row['height']} 4:{row['weight']} \"\n",
    "    + \" \".join([f\"{i + 5}:{value}\" for i, value in enumerate(row.iloc[7:])]) + \"\\n\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt', 'w') as f:\n",
    "    f.writelines(libsvm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffm_model = xl.create_fm() # Use field-aware factorization machine (ffm)\n",
    "ffm_model.setTrain(\"./train.txt\")    # Set the path of training dataset\n",
    "\n",
    "param = {'task':'reg', 'lr':0.2, 'lambda':0.02, 'epoch':3, 'fold':5, 'k':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Cross-validation doesn't support early-stopping. xLearn has already close early-stopping.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 4 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_0.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_1.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_2.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_3.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (./train.txt_4.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 21\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.33 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.48 KB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 1/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.049008            1.016047                0.55\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.038770            1.015497                0.60\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.038548            1.015116                0.66\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 2/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.043965            1.036647                0.55\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.033237            1.037208                0.72\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.033088            1.036496                0.68\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 3/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.042870            1.041658                0.53\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.031904            1.041838                0.60\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.031714            1.041515                0.60\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 4/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.043577            1.034355                0.55\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.033731            1.034821                0.60\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.033632            1.035157                0.60\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Cross-validation: 5/5:\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train mse_loss       Test mse_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  33%\u001b[32m      ]\u001b[0m     1            1.043097            1.041297                0.53\n",
      "\u001b[32m[ \u001b[0m  66%\u001b[32m      ]\u001b[0m     2            1.032313            1.040398                0.61\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m     3            1.032052            1.040399                0.60\n",
      "\u001b[32m[------------] \u001b[0mAverage mse_loss: 1.033737\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish Cross-Validation\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 9.32 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ffm_model.cv(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
